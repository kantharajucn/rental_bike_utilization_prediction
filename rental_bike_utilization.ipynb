{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset summary"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. Dataset size\n",
    "2. Glimpse of dataset\n",
    "3. About variables in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the dataset to pandas dataframe\n",
    "df = pd.read_csv('./dataset/day.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shape of the dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Glimpse of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic info about the dataset \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summary statistics of the dataset \n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Removing unimportant columns\n",
    "\n",
    "1. Date variable can be removed since we have seperate variables for year, month and days.\n",
    "2. Holiday is already addressed in workingday variable and hence this can be removed.\n",
    "3. 'Registered' and 'casual' variables are also dropped since there are leakage variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['dteday', 'holiday', 'casual', 'registered']\n",
    "df.drop(columns, axis=1, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping duplicate rows if any\n",
    "df = df.drop_duplicates(keep='first')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Missing value analysis\n",
    "null_data = df[df.isna().any(axis=1)]\n",
    "null_data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "There are no missing values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using instant as index\n",
    "\n",
    "df = df.set_index('instant')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation of numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Histogram for contineous numerical values\n",
    "num_bins = 10\n",
    "plt.hist(df['cnt'], num_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting distribution function\n",
    "num_bins = 10\n",
    "sns.distplot(df['cnt'], num_bins)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "From the above graph we can infer that the target variable 'count' is normaly distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_columns = ['temp','atemp','hum','windspeed', 'cnt']\n",
    "df_numerical = df[num_columns]\n",
    "df.hist(num_columns, figsize=(10,10), bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising count vs (Month, season, weekday, year, workingday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Box-plot for categorical variable \n",
    "df_season = df.groupby(['season']).agg({'cnt':'sum'})\n",
    "df_season.plot.bar(x=df_season.index.values, y='cnt', rot=0)\n",
    "#box1 = sns.boxplot(x='season', y='cnt')\n",
    "# 1:springer, 2:summer, 3:fall, 4:winter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Year 0:2011 1:2012\n",
    "df_year = df.groupby(['yr']).agg({'cnt':'sum'})\n",
    "df_year.plot.bar(x=df_year.index.values, y='cnt', rot=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Months from Jab to December\n",
    "df_month = df.groupby(['mnth']).agg({'cnt':'sum'})\n",
    "df_month.plot.bar(x=df_month.index.values, y='cnt', rot=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weekday Day of the week\n",
    "df_weekday = df.groupby(['weekday']).agg({'cnt':'sum'})\n",
    "df_weekday.plot.bar(x=df_weekday.index.values, y='cnt', rot=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working day 1: neither weekend nor holiday 0: otherwise\n",
    "df_workingday = df.groupby(['workingday']).agg({'cnt':'sum'})\n",
    "df_workingday.plot.bar(x=df_workingday.index.values, y='cnt', rot=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weathersit\n",
    "#- 1: Clear, Few clouds, Partly cloudy, Partly cloudy\n",
    "#- 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n",
    "#- 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n",
    "#- 4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog\n",
    "df_weathersit = df.groupby(['weathersit']).agg({'cnt':'sum'})\n",
    "df_weathersit.plot.bar(x=df_weathersit.index.values, y='cnt', rot=0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Below ar the inferences made from the above graphs\n",
    "\n",
    "1. Graph for season shows that people uses bike more during fall and summer since it is convenient during these seasons.\n",
    "2. People used bikes more in the year 2012.\n",
    "3. Usage og bike is high from May to September months.\n",
    "4. Graph for variable workingday shows that many people uses bikes during working and very few people uses bikes on weekend or holiday.\n",
    "5. Similarly, people use bike when the weather condition is good. No one uses bike when it is heavy rain with Thunderstorm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corrolation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation with the target variable\n",
    "corrolation = df_numerical.corr()['cnt'][:-1]\n",
    "print(corrolation)\n",
    "#Plotting corrolation plot using pairplot\n",
    "for i in range(0, len(df_numerical.columns), 5):\n",
    "    sns.pairplot(df_numerical, y_vars=['cnt'], x_vars=df_numerical.columns[i:i+5])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "From the pairplot, we can see that temperature and normalised feeling temperatures are positively corelated.\n",
    "Variables huidity and windspeed does not show any correlation with the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.heatmap(df.corr())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "From the Heatmap and pairplot  we can infer that the variables temp, atemp, year, season and month have strong correlation. However, humidity, wind speed and weather variables weak correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "As a first step, I staart with the simple linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping columns windspead and weather and season\n",
    "#unimportant_columns = ['weathersit', 'hum', 'windspeed']\n",
    "#df = df.drop(unimportant_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error, make_scorer, mean_absolute_error\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = shuffle(df)\n",
    "data = df.drop(['cnt'], axis=1)\n",
    "target =  df['cnt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_actual, y_pred):\n",
    "    rms = sqrt(mean_squared_error(y_actual, y_pred))\n",
    "    return rms\n",
    "\n",
    "def rmsle(y, y_):\n",
    "    log1 = np.nan_to_num(np.array([np.log(v + 1) for v in y]))\n",
    "    log2 = np.nan_to_num(np.array([np.log(v + 1) for v in y_]))\n",
    "    calc = (log1 - log2) ** 2\n",
    "    return np.sqrt(np.mean(calc))\n",
    "\n",
    "\n",
    "def print_evaluation_results(actual, predicted):\n",
    "    print(' Test RMSE: {}'.format(rmse(actual, predicted)))\n",
    "    print(' Test RMSLE: {}'.format(rmsle(actual, predicted)))\n",
    "    print(' R squared score: {}'.format(r2_score(actual, predicted)))\n",
    "    print( 'Mean absolute error: {}'.format(mean_absolute_error(actual, predicted)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialising the Linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Splitting the data into train and test.\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, target, test_size=0.2)\n",
    "\n",
    "#Train model\n",
    "model.fit(X= x_train, y=y_train)\n",
    "\n",
    "# Make predictions on test data\n",
    "y_pred = model.predict(X=x_test)\n",
    "print_evaluation_results(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using cross validation"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Since dataset is small, if we are using more data for learning model will not generalize. We can use cross validation to train and test on all the daata. This will help to avoid overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialising the Linear regression model\n",
    "model = LinearRegression()\n",
    "#Train model\n",
    "kf = KFold(n_splits=10)\n",
    "model = LinearRegression()\n",
    "r_squared_score = []\n",
    "rmsle_score = []\n",
    "mae = []\n",
    "for train, test in kf.split(df):\n",
    "    x_train, y_train = data.iloc[train], target.iloc[train]\n",
    "    x_test, y_test = data.iloc[test], target.iloc[test]\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    r_squared_score.append(r2_score(y_test, y_pred))\n",
    "    rmsle_score.append(rmsle(y_test, y_pred))\n",
    "    mae.append(mean_absolute_error(y_test, y_pred))\n",
    "    \n",
    "\n",
    "#Evaluation\n",
    "print('Mean r2 score: {}'.format(np.mean(r_squared_score)))\n",
    "print('Mean rmsle score: {}'.format(np.mean(rmsle_score)))\n",
    "print(' Mean absolute error: {}'.format(np.mean(mae)))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "After using cross validation, R2 score is increase. It means, model is generalised compared to the previous model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using regularization"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Having more number of variables may results in overfitting the model. More variables results in complicated model which sometimes lacks generalisation power. In this case, L1 regularisation(Lasso) is best suited to reduce the coefficients and produce simpler models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into train and test.\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, target, test_size=.2)\n",
    "\n",
    "#Model\n",
    "lasso_m_ = Lasso()\n",
    "\n",
    "#Hyper parameters\n",
    "alpha  = [0.001, 0.005, 0.01 ,0.1, 0.2, 0.3, 0.5, 0.7, 1]\n",
    "lasso_params_ = { 'max_iter':[500],'alpha':alpha}\n",
    "\n",
    "#Evaluation measure\n",
    "evaluation_measure = make_scorer(rmsle, greater_is_better=False)\n",
    "grid_lasso = GridSearchCV( lasso_m_,\n",
    "                          lasso_params_,\n",
    "                          scoring = evaluation_measure,\n",
    "                          cv=20)\n",
    "\n",
    "grid_lasso.fit(X = x_train,y = y_train)\n",
    "y_pred = grid_lasso.predict(X= x_test)\n",
    "print (grid_lasso.best_params_)\n",
    "print_evaluation_results(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "After applying regularisation, RMSLE and R2 scores are better when the alpha value is 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Ensemble methods"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Ensembles models are nothing but combing weak models into single model to improve predictive power and stability of teh model.\n",
    "\n",
    "Ensemble models helps to improve the performance by\n",
    "\n",
    "1. Avoid overfitting\n",
    "2. Rank the features.\n",
    "3. Reduce variance.\n",
    "4. Averaging the bias.\n",
    "\n",
    "I am using random forest regressor for this task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into train and test.\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, target, test_size=.2)\n",
    "\n",
    "#Model initialisation\n",
    "model = RandomForestRegressor(n_estimators=100)\n",
    "#Model\n",
    "\n",
    "#Hyper parameters\n",
    "n_estimators = [50, 100, 200, 300]\n",
    "\n",
    "parameters = { 'n_estimators':[50, 100, 200, 300],'max_features': [2, 3, 4, 5, 6]}\n",
    "\n",
    "#Evaluation measure\n",
    "evaluation_measure = make_scorer(rmsle, greater_is_better=False)\n",
    "grid_random_forest = GridSearchCV( model,\n",
    "                          parameters,\n",
    "                          scoring = evaluation_measure,\n",
    "                          cv=10)\n",
    "\n",
    "grid_random_forest.fit(X = x_train,y = y_train)\n",
    "y_pred = grid_random_forest.predict(X= x_test)\n",
    "print (grid_random_forest.best_params_)\n",
    "print_evaluation_results(y_test, y_pred)\n",
    "\n",
    "# Save model\n",
    "file_name = 'randome_forest.sav'\n",
    "pickle.dump(grid_random_forest, open(file_name, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean absolute deviation on predictions : {}'.format(pd.Series(y_pred).mad()))\n",
    "print('Mean absolute deviation on actuals: {}'.format(pd.Series(y_test).mad()))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "When compared to all the previous models, Ensemble based RandomForest regressor performing better with R2 score of 0.89, RMSLE score of 0.24 and Mean absolute error of 460 when n_estimators are 50 and features 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
